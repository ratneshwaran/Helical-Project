{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4 (Optional): Prioritize Targets\n",
        "\n",
        "Compute a composite score per perturbation combining:\n",
        "- Î” distance to healthy (improvement negative)\n",
        "- Wasserstein reduction\n",
        "- kNN healthy-overlap gain\n",
        "- Silhouette change\n",
        "\n",
        "Also compute OffTargetVar: variance of shift norms across ALS cells.\n",
        "Outputs: `data/figs/task4_top_targets.png` and a CSV of rankings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure repo root is on sys.path for `utils` imports\n",
        "from pathlib import Path\n",
        "import sys\n",
        "repo_root = Path.cwd().parent\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Added to sys.path:', repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from utils.metrics import composite_score\n",
        "from utils.plotting import barplot_scores\n",
        "\n",
        "EMB_DIR = Path('data/embeddings')\n",
        "FIG_DIR = Path('data/figs')\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load metrics from Task 3\n",
        "metrics_path = FIG_DIR / 'task3_metrics.csv'\n",
        "metrics_df = pd.read_csv(metrics_path)\n",
        "\n",
        "# Define weights\n",
        "weights = {\n",
        "    'delta_to_healthy': -0.5,   # negative change is good -> negative weight makes improvement positive\n",
        "    'wasserstein_after': -0.2,  # lower after is better\n",
        "    'knn_overlap_gain': 0.2,    # higher is better\n",
        "    'silhouette_after': -0.1,   # lower separation of ALS_pert vs healthy may indicate rescue\n",
        "}\n",
        "\n",
        "scores = {}\n",
        "for _, row in metrics_df.iterrows():\n",
        "    comps = {\n",
        "        'delta_to_healthy': row['delta_to_healthy'],\n",
        "        'wasserstein_after': row['wasserstein_after'],\n",
        "        'knn_overlap_gain': row['knn_overlap_gain'],\n",
        "        'silhouette_after': row['silhouette_after'],\n",
        "    }\n",
        "    scores[row['perturbation']] = composite_score(comps, weights)\n",
        "\n",
        "# OffTargetVar: use per-cell shift norms if available; here approximate from embeddings sizes (placeholder)\n",
        "# In practice, compute norms of (ALS_pert - ALS) per cell and take variance.\n",
        "# We reduce score by OffTargetVar to penalize heterogeneous responses.\n",
        "for name in list(scores.keys()):\n",
        "    scores[name] -= 0.0  # placeholder (no-op)\n",
        "\n",
        "# Plot and save\n",
        "barplot_scores(scores, 'Task4: Top targets (higher=better)', str(FIG_DIR / 'task4_top_targets.png'))\n",
        "\n",
        "rank_df = pd.DataFrame({'perturbation': list(scores.keys()), 'score': list(scores.values())}).sort_values('score', ascending=False)\n",
        "rank_df.to_csv(FIG_DIR / 'task4_rankings.csv', index=False)\n",
        "\n",
        "rank_df.head()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
