{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Apply Perturbations to ALS Genes and Embed (Geneformer V2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added to sys.path: /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer\n"
          ]
        }
      ],
      "source": [
        "# Ensure repo root is on sys.path for `utils` imports\n",
        "from pathlib import Path\n",
        "import sys\n",
        "repo_root = Path.cwd().parent\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Added to sys.path:', repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PIP_CACHE_DIR\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache\"\n",
        "os.environ[\"HF_HOME\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache/huggingface\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache/transformers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# export LD_LIBRARY_PATH=\"/cs/student/projects1/aibh/2024/rmaheswa/python-3.10/lib:$LD_LIBRARY_PATH\"\n",
        "# export JUPYTER_PATH=\"/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/helical-env-310-share\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA available: True\n",
            "GPU count: 1\n",
            "Current GPU: NVIDIA GeForce RTX 3090 Ti\n",
            "GPU memory: 25.3 GB\n"
          ]
        }
      ],
      "source": [
        "# Environment variables are now automatically set by the virtual environment\n",
        "# Verify PyTorch GPU availability\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  SUBSET_SIZE: 5000 (None = full dataset)\n",
            "  BATCH_SIZE: 16\n",
            "  TOP_K: 4096\n",
            "  GPU available: True\n",
            "  GPU memory: 25.3 GB\n"
          ]
        }
      ],
      "source": [
        "# Configuration for memory management\n",
        "# Set SUBSET_SIZE to None to use full dataset, or a number to use subset\n",
        "SUBSET_SIZE = 5000  # Use 5000 cells per group for testing\n",
        "BATCH_SIZE = 16     # Batch size for Geneformer embeddings\n",
        "TOP_K = 4096        # Number of top genes to use for ranking\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  SUBSET_SIZE: {SUBSET_SIZE} (None = full dataset)\")\n",
        "print(f\"  BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"  TOP_K: {TOP_K}\")\n",
        "print(f\"  GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/.venv-gf310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/.venv-gf310/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading baseline data...\n",
            "Loaded AnnData: 112014 cells, 22026 genes\n",
            "Using subset size: 5000 cells per group (set SUBSET_SIZE=None for full dataset)\n",
            "Using 'Condition' column for grouping\n",
            "Available conditions: {'ALS': 66960, 'PN': 45054}\n",
            "Healthy cells: 45054\n",
            "ALS cells: 66960\n",
            "Subsetting to 5000 cells per group...\n",
            "After subsetting - Healthy: 5000, ALS: 5000\n",
            "Applying perturbations...\n",
            "✓ Perturbations complete\n",
            "Initializing Geneformer embedder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at ctheodoris/Geneformer and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for healthy baseline...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'TranscriptomeTokenizer' object has no attribute 'get_vocab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m embedder \u001b[38;5;241m=\u001b[39m GFEmbedder()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings for healthy baseline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m healthy_tokens \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madata_to_rank_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhealthy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_K\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m healthy_emb \u001b[38;5;241m=\u001b[39m embedder\u001b[38;5;241m.\u001b[39mget_cls_embeddings(healthy_tokens, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m     84\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(EMB_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhealthy_base.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, arr\u001b[38;5;241m=\u001b[39mhealthy_emb)\n",
            "File \u001b[0;32m/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/utils/geneformer_helpers.py:86\u001b[0m, in \u001b[0;36mGFEmbedder.adata_to_rank_tokens\u001b[0;34m(self, adata, top_k)\u001b[0m\n\u001b[1;32m     83\u001b[0m n_cells, n_genes \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     84\u001b[0m gene_symbols \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m, adata\u001b[38;5;241m.\u001b[39mvar_names)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 86\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_vocab_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffline:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/utils/geneformer_helpers.py:67\u001b[0m, in \u001b[0;36mGFEmbedder._get_vocab_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Assumes tokenizer vocab keys are gene symbols\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocab\u001b[49m()\u001b[38;5;241m.\u001b[39mkeys())\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TranscriptomeTokenizer' object has no attribute 'get_vocab'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import anndata as ad\n",
        "import gc\n",
        "from utils.io import ensure_dirs\n",
        "from utils.perturb import batch_perturb\n",
        "from utils.geneformer_helpers import GFEmbedder\n",
        "from utils.plotting import umap_2d, plot_umap\n",
        "\n",
        "ensure_dirs()\n",
        "AD_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/adata')\n",
        "EMB_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/embeddings')\n",
        "FIG_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/figs')\n",
        "\n",
        "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load baseline AnnData\n",
        "baseline_path = AD_DIR / 'baseline.h5ad'\n",
        "if not baseline_path.exists():\n",
        "    raise FileNotFoundError(\"Missing data/adata/baseline.h5ad. Run: make prep\")\n",
        "\n",
        "print(\"Loading baseline data...\")\n",
        "adata = ad.read_h5ad(baseline_path)\n",
        "print(f\"Loaded AnnData: {adata.n_obs} cells, {adata.n_vars} genes\")\n",
        "\n",
        "# Use configuration from previous cell\n",
        "print(f\"Using subset size: {SUBSET_SIZE} cells per group (set SUBSET_SIZE=None for full dataset)\")\n",
        "\n",
        "als_genes = [\"C9orf72\",\"SOD1\",\"TARDBP\",\"FUS\",\"TBK1\",\"NEK1\"]\n",
        "\n",
        "# Build gene_sets with _up/_down variants\n",
        "up_sets = {f\"{g}_up\": [g] for g in als_genes}\n",
        "down_sets = {f\"{g}_down\": [g] for g in als_genes}\n",
        "\n",
        "# Split healthy vs ALS by obs labels\n",
        "# Check for Condition column (capital C) first, then fall back to Group\n",
        "if 'Condition' in adata.obs.columns:\n",
        "    print(\"Using 'Condition' column for grouping\")\n",
        "    print(f\"Available conditions: {adata.obs['Condition'].value_counts().to_dict()}\")\n",
        "    # PN = presumably healthy/control, ALS = disease\n",
        "    healthy = adata[adata.obs['Condition'] == 'PN'].copy()\n",
        "    als = adata[adata.obs['Condition'] == 'ALS'].copy()\n",
        "elif 'Group' in adata.obs.columns:\n",
        "    print(\"Using 'Group' column for grouping\")\n",
        "    print(f\"Available groups: {adata.obs['Group'].value_counts().to_dict()}\")\n",
        "    # PN = presumably healthy/control, SALS = Sporadic ALS\n",
        "    healthy = adata[adata.obs['Group'] == 'PN'].copy()\n",
        "    als = adata[adata.obs['Group'] == 'SALS'].copy()\n",
        "else:\n",
        "    raise ValueError(\"Required obs column 'Condition' or 'Group' not found. Please add condition labels to baseline AnnData.\")\n",
        "\n",
        "print(f\"Healthy cells: {healthy.n_obs}\")\n",
        "print(f\"ALS cells: {als.n_obs}\")\n",
        "\n",
        "# Apply subsetting if specified\n",
        "if SUBSET_SIZE is not None:\n",
        "    print(f\"Subsetting to {SUBSET_SIZE} cells per group...\")\n",
        "    if healthy.n_obs > SUBSET_SIZE:\n",
        "        healthy = healthy[:SUBSET_SIZE].copy()\n",
        "    if als.n_obs > SUBSET_SIZE:\n",
        "        als = als[:SUBSET_SIZE].copy()\n",
        "    print(f\"After subsetting - Healthy: {healthy.n_obs}, ALS: {als.n_obs}\")\n",
        "\n",
        "# Clear memory\n",
        "gc.collect()\n",
        "\n",
        "print(\"Applying perturbations...\")\n",
        "# a) healthy -> ALS-like (up)\n",
        "pert_rank_up = batch_perturb(healthy, up_sets, mode='rank', direction='up', delta_percentile=0.15)\n",
        "# b) ALS -> rescue (down)\n",
        "pert_rank_down = batch_perturb(als, down_sets, mode='rank', direction='down', delta_percentile=0.15)\n",
        "\n",
        "print(\"✓ Perturbations complete\")\n",
        "gc.collect()\n",
        "\n",
        "# Geneformer embeddings\n",
        "print(\"Initializing Geneformer embedder...\")\n",
        "embedder = GFEmbedder()\n",
        "\n",
        "print(\"Generating embeddings for healthy baseline...\")\n",
        "healthy_tokens = embedder.adata_to_rank_tokens(healthy, top_k=TOP_K)\n",
        "healthy_emb = embedder.get_cls_embeddings(healthy_tokens, batch_size=BATCH_SIZE)\n",
        "np.savez(EMB_DIR / 'healthy_base.npz', arr=healthy_emb)\n",
        "print(f\"✓ Saved healthy baseline embeddings: {healthy_emb.shape}\")\n",
        "del healthy_tokens\n",
        "gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for ALS baseline...\")\n",
        "als_tokens = embedder.adata_to_rank_tokens(als, top_k=TOP_K)\n",
        "als_emb = embedder.get_cls_embeddings(als_tokens, batch_size=BATCH_SIZE)\n",
        "np.savez(EMB_DIR / 'als_base.npz', arr=als_emb)\n",
        "print(f\"✓ Saved ALS baseline embeddings: {als_emb.shape}\")\n",
        "del als_tokens\n",
        "gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for healthy perturbations...\")\n",
        "for name, adx in pert_rank_up.items():\n",
        "    print(f\"  Processing {name}...\")\n",
        "    toks = embedder.adata_to_rank_tokens(adx, top_k=TOP_K)\n",
        "    emb = embedder.get_cls_embeddings(toks, batch_size=BATCH_SIZE)\n",
        "    np.savez(EMB_DIR / f'healthy_{name}.npz', arr=emb)\n",
        "    print(f\"  ✓ Saved {name}: {emb.shape}\")\n",
        "    del toks, emb\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for ALS perturbations...\")\n",
        "for name, adx in pert_rank_down.items():\n",
        "    print(f\"  Processing {name}...\")\n",
        "    toks = embedder.adata_to_rank_tokens(adx, top_k=TOP_K)\n",
        "    emb = embedder.get_cls_embeddings(toks, batch_size=BATCH_SIZE)\n",
        "    np.savez(EMB_DIR / f'als_{name}.npz', arr=emb)\n",
        "    print(f\"  ✓ Saved {name}: {emb.shape}\")\n",
        "    del toks, emb\n",
        "    gc.collect()\n",
        "\n",
        "# Optional: quick UMAP preview across subsets\n",
        "stack = np.vstack([healthy_emb, als_emb])\n",
        "labels = ['healthy']*len(healthy_emb) + ['als']*len(als_emb)\n",
        "pts = umap_2d(stack)\n",
        "plot_umap(pts, labels, 'Task2: Healthy vs ALS (baseline)', str(FIG_DIR / 'task2_embedding_snapshot.png'))\n",
        "\n",
        "print('Saved embeddings to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/embeddings and snapshot figure to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/figs.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note on model download: If model download is blocked, set the environment variable `GF_OFFLINE=1` to use deterministic pseudo-embeddings for smoke tests.\n",
        "\n",
        "When running with a GPU, embeddings will be computed using the actual Geneformer V2 model.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-gf310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
