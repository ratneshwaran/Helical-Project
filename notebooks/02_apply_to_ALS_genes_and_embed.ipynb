{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Apply Perturbations to ALS Genes and Embed (Geneformer V2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added to sys.path: /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer\n"
          ]
        }
      ],
      "source": [
        "# Ensure repo root is on sys.path for `utils` imports\n",
        "from pathlib import Path\n",
        "import sys\n",
        "repo_root = Path.cwd().parent\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Added to sys.path:', repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PIP_CACHE_DIR\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache\"\n",
        "os.environ[\"HF_HOME\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache/huggingface\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/cs/student/projects1/aibh/2024/rmaheswa/cache/transformers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# export LD_LIBRARY_PATH=\"/cs/student/projects1/aibh/2024/rmaheswa/python-3.10/lib:$LD_LIBRARY_PATH\"\n",
        "# export JUPYTER_PATH=\"/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/helical-env-310-share\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA available: True\n",
            "GPU count: 1\n",
            "Current GPU: NVIDIA GeForce RTX 3090 Ti\n",
            "GPU memory: 25.3 GB\n"
          ]
        }
      ],
      "source": [
        "# Environment variables are now automatically set by the virtual environment\n",
        "# Verify PyTorch GPU availability\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  SUBSET_SIZE: 500 (None = full dataset)\n",
            "  BATCH_SIZE: 128\n",
            "  TOP_K: 4096\n",
            "  GPU available: True\n",
            "  GPU memory: 25.3 GB\n"
          ]
        }
      ],
      "source": [
        "# Configuration for memory management\n",
        "# Set SUBSET_SIZE to None to use full dataset, or a number to use subset\n",
        "SUBSET_SIZE = 500  # Use 5000 cells per group for testing\n",
        "BATCH_SIZE = 128    # Batch size for Geneformer embeddings\n",
        "TOP_K = 4096        # Number of top genes to use for ranking\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  SUBSET_SIZE: {SUBSET_SIZE} (None = full dataset)\")\n",
        "print(f\"  BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"  TOP_K: {TOP_K}\")\n",
        "print(f\"  GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Speed overrides (optional)\n",
        "# Increase batch size to utilize GPU; reduce TOP_K for faster tokenization/forward\n",
        "# BATCH_SIZE = 64\n",
        "# TOP_K = 4096\n",
        "# print(f\"BATCH_SIZE={BATCH_SIZE}, TOP_K={TOP_K}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/.venv-gf310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/.venv-gf310/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import anndata as ad\n",
        "import gc\n",
        "from utils.io import ensure_dirs\n",
        "from utils.perturb import batch_perturb\n",
        "from utils.geneformer_helpers import GFEmbedder\n",
        "\n",
        "from importlib import reload\n",
        "import utils.geneformer_helpers as gfh\n",
        "gfh = reload(gfh)\n",
        "from utils.geneformer_helpers import GFEmbedder  # re-import after reload\n",
        "\n",
        "import geneformer, inspect\n",
        "from utils.plotting import umap_2d, plot_umap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ALS gene list (sources)\n",
        "We target established ALS-associated genes for demonstration: C9orf72, SOD1, TARDBP (TDP-43), FUS, TBK1, NEK1. These are supported by familial ALS variants, GWAS, and functional studies (e.g., toxic gain-of-function for mutant SOD1 and C9orf72 HREs; haploinsufficiency for TBK1/NEK1; dosage sensitivity for TARDBP/FUS). See: NCBI GeneReviews and recent ALS genetics reviews (PMC/ScienceDirect) for summaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading baseline data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded AnnData: 112014 cells, 22026 genes\n",
            "Using subset size: 500 cells per group (set SUBSET_SIZE=None for full dataset)\n",
            "Using 'Condition' column for grouping\n",
            "Available conditions: {'ALS': 66960, 'PN': 45054}\n",
            "Healthy cells: 45054\n",
            "ALS cells: 66960\n",
            "Subsetting to 500 cells per group...\n",
            "After subsetting - Healthy: 500, ALS: 500\n",
            "Applying perturbations with gene-specific rules...\n",
            "Healthy perturbations: ['SOD1_up', 'FUS_up', 'TBK1_down', 'NEK1_down', 'TARDBP_up_mild', 'TARDBP_down_mild', 'C9orf72_up', 'C9orf72_down']\n",
            "ALS perturbations: ['SOD1_down', 'FUS_down', 'TBK1_up', 'NEK1_up', 'TARDBP_up_mild', 'TARDBP_down_mild', 'C9orf72_down', 'C9orf72_up']\n",
            "✓ Perturbations prepared\n",
            "Initializing Geneformer embedder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at ctheodoris/Geneformer and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer coverage: 17986/22026 (81.7%)\n",
            "Generating embeddings for healthy baseline...\n",
            "✓ Saved healthy baseline embeddings: (500, 768)\n",
            "Generating embeddings for ALS baseline...\n",
            "✓ Saved ALS baseline embeddings: (500, 768)\n",
            "Generating embeddings for healthy perturbations...\n",
            "  Processing SOD1_up...\n",
            "  ✓ Saved SOD1_up: (500, 768)\n",
            "  Processing FUS_up...\n",
            "  ✓ Saved FUS_up: (500, 768)\n",
            "  Processing TBK1_down...\n",
            "  ✓ Saved TBK1_down: (500, 768)\n",
            "  Processing NEK1_down...\n",
            "  ✓ Saved NEK1_down: (500, 768)\n",
            "  Processing TARDBP_up_mild...\n",
            "  ✓ Saved TARDBP_up_mild: (500, 768)\n",
            "  Processing TARDBP_down_mild...\n",
            "  ✓ Saved TARDBP_down_mild: (500, 768)\n",
            "  Processing C9orf72_up...\n",
            "  ✓ Saved C9orf72_up: (500, 768)\n",
            "  Processing C9orf72_down...\n",
            "  ✓ Saved C9orf72_down: (500, 768)\n",
            "Generating embeddings for ALS perturbations...\n",
            "  Processing SOD1_down...\n",
            "  ✓ Saved SOD1_down: (500, 768)\n",
            "  Processing FUS_down...\n",
            "  ✓ Saved FUS_down: (500, 768)\n",
            "  Processing TBK1_up...\n",
            "  ✓ Saved TBK1_up: (500, 768)\n",
            "  Processing NEK1_up...\n",
            "  ✓ Saved NEK1_up: (500, 768)\n",
            "  Processing TARDBP_up_mild...\n",
            "  ✓ Saved TARDBP_up_mild: (500, 768)\n",
            "  Processing TARDBP_down_mild...\n",
            "  ✓ Saved TARDBP_down_mild: (500, 768)\n",
            "  Processing C9orf72_down...\n",
            "  ✓ Saved C9orf72_down: (500, 768)\n",
            "  Processing C9orf72_up...\n",
            "  ✓ Saved C9orf72_up: (500, 768)\n",
            "Saved embeddings to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/embeddings and snapshot figure to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/figs.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "ensure_dirs()\n",
        "AD_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/adata')\n",
        "EMB_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/embeddings')\n",
        "FIG_DIR = Path('/cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/figs')\n",
        "\n",
        "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load baseline AnnData\n",
        "baseline_path = AD_DIR / 'baseline.h5ad'\n",
        "if not baseline_path.exists():\n",
        "    raise FileNotFoundError(\"Missing data/adata/baseline.h5ad. Run: make prep\")\n",
        "\n",
        "print(\"Loading baseline data...\")\n",
        "adata = ad.read_h5ad(baseline_path)\n",
        "print(f\"Loaded AnnData: {adata.n_obs} cells, {adata.n_vars} genes\")\n",
        "\n",
        "# Use configuration from previous cell\n",
        "print(f\"Using subset size: {SUBSET_SIZE} cells per group (set SUBSET_SIZE=None for full dataset)\")\n",
        "\n",
        "# Gene-specific configuration per feedback\n",
        "GOF = [\"SOD1\", \"FUS\"]          # gain-of-function/toxic when increased\n",
        "LOF = [\"TBK1\", \"NEK1\"]         # loss-of-function; decreasing worsens\n",
        "DOSAGE = [\"TARDBP\"]            # dosage sensitive; both too high/low are harmful\n",
        "SPECIAL = [\"C9orf72\"]          # split interpretation (HRE/DPR vs protein)\n",
        "\n",
        "# Split healthy vs ALS by obs labels\n",
        "# Check for Condition column (capital C) first, then fall back to Group\n",
        "if 'Condition' in adata.obs.columns:\n",
        "    print(\"Using 'Condition' column for grouping\")\n",
        "    print(f\"Available conditions: {adata.obs['Condition'].value_counts().to_dict()}\")\n",
        "    healthy = adata[adata.obs['Condition'] == 'PN'].copy()\n",
        "    als = adata[adata.obs['Condition'] == 'ALS'].copy()\n",
        "elif 'Group' in adata.obs.columns:\n",
        "    print(\"Using 'Group' column for grouping\")\n",
        "    print(f\"Available groups: {adata.obs['Group'].value_counts().to_dict()}\")\n",
        "    healthy = adata[adata.obs['Group'] == 'PN'].copy()\n",
        "    als = adata[adata.obs['Group'] == 'SALS'].copy()\n",
        "else:\n",
        "    raise ValueError(\"Required obs column 'Condition' or 'Group' not found. Please add condition labels to baseline AnnData.\")\n",
        "\n",
        "print(f\"Healthy cells: {healthy.n_obs}\")\n",
        "print(f\"ALS cells: {als.n_obs}\")\n",
        "\n",
        "# Apply subsetting if specified\n",
        "if SUBSET_SIZE is not None:\n",
        "    print(f\"Subsetting to {SUBSET_SIZE} cells per group...\")\n",
        "    if healthy.n_obs > SUBSET_SIZE:\n",
        "        healthy = healthy[:SUBSET_SIZE].copy()\n",
        "    if als.n_obs > SUBSET_SIZE:\n",
        "        als = als[:SUBSET_SIZE].copy()\n",
        "    print(f\"After subsetting - Healthy: {healthy.n_obs}, ALS: {als.n_obs}\")\n",
        "\n",
        "# Clear memory\n",
        "gc.collect()\n",
        "\n",
        "from utils.perturb import knock_rank, knock_expr\n",
        "\n",
        "print(\"Applying perturbations with gene-specific rules...\")\n",
        "healthy_perts = {}\n",
        "als_perts = {}\n",
        "\n",
        "# Helpers\n",
        "def add_rank(dst, adx, gene, direction, delta=0.15, tag=None):\n",
        "    name = f\"{gene}_{direction}\" if tag is None else tag\n",
        "    dst[name] = knock_rank(adx, genes=[gene], direction=direction, delta_percentile=delta)\n",
        "\n",
        "def add_expr(dst, adx, gene, direction, log2fc=0.3, propagate=True, k_neighbors=20, tag=None):\n",
        "    name = f\"{gene}_{direction}_mild\" if tag is None else tag\n",
        "    dst[name] = knock_expr(adx, genes=[gene], direction=direction, log2fc=log2fc, propagate=propagate, k_neighbors=k_neighbors)\n",
        "\n",
        "# GOF: up in healthy (mimic), down in ALS (rescue)\n",
        "for g in GOF:\n",
        "    add_rank(healthy_perts, healthy, g, 'up', delta=0.15)\n",
        "    add_rank(als_perts, als, g, 'down', delta=0.15)\n",
        "\n",
        "# LOF: down in healthy (mimic), up in ALS (rescue)\n",
        "for g in LOF:\n",
        "    add_rank(healthy_perts, healthy, g, 'down', delta=0.15)\n",
        "    add_rank(als_perts, als, g, 'up', delta=0.15)\n",
        "\n",
        "# DOSAGE sensitive (TARDBP): test mild up and mild down in both cohorts\n",
        "for g in DOSAGE:\n",
        "    add_expr(healthy_perts, healthy, g, 'up', log2fc=0.3)\n",
        "    add_expr(healthy_perts, healthy, g, 'down', log2fc=0.3)\n",
        "    add_expr(als_perts, als, g, 'up', log2fc=0.3)\n",
        "    add_expr(als_perts, als, g, 'down', log2fc=0.3)\n",
        "\n",
        "# SPECIAL C9orf72: include both directions in ALS (HRE lowering vs protein restoration)\n",
        "for g in SPECIAL:\n",
        "    add_rank(healthy_perts, healthy, g, 'up', delta=0.15)   # mimic GoF repeat toxicity\n",
        "    add_rank(healthy_perts, healthy, g, 'down', delta=0.15) # mimic potential protein LoF\n",
        "    add_rank(als_perts, als, g, 'down', delta=0.15)         # HRE/DPR lowering surrogate\n",
        "    add_rank(als_perts, als, g, 'up', delta=0.15)           # protein restoration surrogate\n",
        "\n",
        "print(f\"Healthy perturbations: {list(healthy_perts.keys())}\")\n",
        "print(f\"ALS perturbations: {list(als_perts.keys())}\")\n",
        "\n",
        "print(\"✓ Perturbations prepared\")\n",
        "gc.collect()\n",
        "\n",
        "# Geneformer embeddings\n",
        "print(\"Initializing Geneformer embedder...\")\n",
        "embedder = GFEmbedder()\n",
        "\n",
        "# Sanity: tokenizer vocab coverage on this dataset\n",
        "try:\n",
        "    syms = healthy.var.get(\"gene_symbol\", healthy.var_names).astype(str)\n",
        "    mapped = [s if s.upper().startswith(\"ENSG\") else embedder.gene_name_to_ensembl.get(s.upper(), None) for s in syms]\n",
        "    present = [g for g in mapped if (g is not None) and (g in embedder.tokenizer.gene_token_dict)]\n",
        "    cov = len(present) / max(1, len(mapped))\n",
        "    print(f\"Tokenizer coverage: {len(present)}/{len(mapped)} ({cov:.1%})\")\n",
        "except Exception as e:\n",
        "    print(\"Tokenizer coverage check skipped:\", e)\n",
        "\n",
        "print(\"Generating embeddings for healthy baseline...\")\n",
        "h_base_path = EMB_DIR / 'healthy_base.npz'\n",
        "if not h_base_path.exists():\n",
        "    healthy_tokens = embedder.adata_to_rank_tokens(healthy, top_k=TOP_K)\n",
        "    healthy_emb = embedder.get_cls_embeddings(healthy_tokens, batch_size=BATCH_SIZE)\n",
        "    np.savez(h_base_path, arr=healthy_emb)\n",
        "    print(f\"✓ Saved healthy baseline embeddings: {healthy_emb.shape}\")\n",
        "    del healthy_tokens\n",
        "else:\n",
        "    healthy_emb = np.load(h_base_path)['arr']\n",
        "    print(f\"✓ Skipped (exists): {h_base_path.name} -> {healthy_emb.shape}\")\n",
        "gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for ALS baseline...\")\n",
        "a_base_path = EMB_DIR / 'als_base.npz'\n",
        "if not a_base_path.exists():\n",
        "    als_tokens = embedder.adata_to_rank_tokens(als, top_k=TOP_K)\n",
        "    als_emb = embedder.get_cls_embeddings(als_tokens, batch_size=BATCH_SIZE)\n",
        "    np.savez(a_base_path, arr=als_emb)\n",
        "    print(f\"✓ Saved ALS baseline embeddings: {als_emb.shape}\")\n",
        "    del als_tokens\n",
        "else:\n",
        "    als_emb = np.load(a_base_path)['arr']\n",
        "    print(f\"✓ Skipped (exists): {a_base_path.name} -> {als_emb.shape}\")\n",
        "gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for healthy perturbations...\")\n",
        "for name, adx in healthy_perts.items():\n",
        "    outp = EMB_DIR / f'healthy_{name}.npz'\n",
        "    if outp.exists():\n",
        "        print(f\"  ✓ Skipped (exists): {outp.name}\")\n",
        "        continue\n",
        "    print(f\"  Processing {name}...\")\n",
        "    toks = embedder.adata_to_rank_tokens(adx, top_k=TOP_K)\n",
        "    emb = embedder.get_cls_embeddings(toks, batch_size=BATCH_SIZE)\n",
        "    np.savez(outp, arr=emb)\n",
        "    print(f\"  ✓ Saved {name}: {emb.shape}\")\n",
        "    del toks, emb\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Generating embeddings for ALS perturbations...\")\n",
        "for name, adx in als_perts.items():\n",
        "    outp = EMB_DIR / f'als_{name}.npz'\n",
        "    if outp.exists():\n",
        "        print(f\"  ✓ Skipped (exists): {outp.name}\")\n",
        "        continue\n",
        "    print(f\"  Processing {name}...\")\n",
        "    toks = embedder.adata_to_rank_tokens(adx, top_k=TOP_K)\n",
        "    emb = embedder.get_cls_embeddings(toks, batch_size=BATCH_SIZE)\n",
        "    np.savez(outp, arr=emb)\n",
        "    print(f\"  ✓ Saved {name}: {emb.shape}\")\n",
        "    del toks, emb\n",
        "    gc.collect()\n",
        "\n",
        "# Optional: quick UMAP preview across subsets\n",
        "stack = np.vstack([healthy_emb, als_emb])\n",
        "labels = ['healthy']*len(healthy_emb) + ['als']*len(als_emb)\n",
        "pts = umap_2d(stack)\n",
        "plot_umap(pts, labels, 'Task2: Healthy vs ALS (baseline)', str(FIG_DIR / 'task2_embedding_snapshot.png'))\n",
        "\n",
        "print('Saved embeddings to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/embeddings and snapshot figure to /cs/student/projects1/aibh/2024/rmaheswa/Helical_Task/als-perturb-geneformer/als-perturb-geneformer/data/figs.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'FIG_DIR' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Display UMAP snapshot\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[0;32m----> 3\u001b[0m fig_path \u001b[38;5;241m=\u001b[39m \u001b[43mFIG_DIR\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask2_embedding_snapshot.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplaying UMAP snapshot from Task 2:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FIG_DIR' is not defined"
          ]
        }
      ],
      "source": [
        "# Display UMAP snapshot\n",
        "from IPython.display import Image, display\n",
        "fig_path = FIG_DIR / 'task2_embedding_snapshot.png'\n",
        "if fig_path.exists():\n",
        "    print(f\"Displaying UMAP snapshot from Task 2:\")\n",
        "    display(Image(str(fig_path)))\n",
        "else:\n",
        "    print(f\"Figure not found at: {fig_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-gf310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
